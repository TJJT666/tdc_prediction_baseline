{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 1 模型介绍\n",
    "此项目采用经典的LSTM编解码器实现机动车的轨迹预测。在该任务中，输入为观测到的车辆历史轨迹信息，输出为预测的未来车辆轨迹。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0b27a773db3ec34"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.1 模型概述\n",
    "LSTM Encoder-Decoder是最常见的sequence-to-sequence（seq2seq）模型，最早由2014年的经典论文[《Sequence to Sequence Learning with Neural Networks》](https://arxiv.org/abs/1409.3215)提出，被引量已经过万。该模型的基本思想是用一个RNN网络（编码器）来将输入的序列编码为一个固定长度的向量（context vector），该向量可以被视为整个输入序列的一个抽象表示，然后将该向量作为另一个RNN网络（解码器）的初始输入，并输出任意长度的目标序列。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2401e381afc62ab7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.2 模型架构\n",
    "- Encoder采用了一层全连接层，四层LSTM，并且采用了dropout来降低过拟合；\n",
    "- Decoder的结构和Encoder的结构基本一致，区别在于Decoder每次接受输入的序列长度只有1，然后每次Decoder的输出都作为下一个时间点的预测。\n",
    "- 最终的Seq2Seq模型结合了Encoder和Decoder，Encoder将输入的所有历史时间步的轨迹编码为一个context vector，然后将其作为Decoder的初始输入，并将Encoder最终的hidden state和cell state作为Decoder初始的hidden state和cell state，重复使用Decoder来预测下一个时间点的预测，最终输出所有未来时间步的预测轨迹。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c767a31188e9e2d9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 1.3 具体实现\n",
    "- **数据预处理**：主要是从csv格式的数据中提取和整理轨迹信息，这里为了能达到较好训练效果，采用前后时刻的位移矢量而非绝对坐标作为模型输入。\n",
    "- **训练**：采用了常用的teacher-forcing技巧，即训练的时候Decoder的输入按照一定概率为上一次的输出或者真实的当前时间点的数据，使得网络能够一定程度上避免时序预测的缺陷：初始预测偏离而导致后续结果受到影响。\n",
    "- **测试/评估**：使用训练好的模型对所有测试数据进行预测，计算出所需的评价指标。为了保证评估结果的客观性，不使用teacher-forcing。\n",
    "- **可视化**：使用训练好的模型对部分测试数据进行预测，绘制出历史轨迹、真实轨迹和预测轨迹。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f1f6e2ddba3974"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2 本地部署\n",
    "- 此项目可以下载至本地进行部署\n",
    "- 设备要求：Windows/Linux环境下运行，预装Anaconda/Miniconda；\n",
    "- 若有英伟达的独立显卡且配置好cuda核，默认采用独立显卡进行训练，否则采用cpu进行；\n",
    "- 单张4070Ti训练500轮大概需要8min，项目中给出了采用gpu训练好的案例模型，即results/model/example_best_seq2seq.pt；若采用cpu运行则速度较慢，运行200轮也可以达到一定效果"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74b12ca0dcab573"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.1 数据集下载和准备\n",
    "采用的是SinD数据集中提取的部分左转车辆的轨迹片段，数据量较小，代码中的data文件夹已经给出，不需要额外进行下载。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ccc8f0772020360a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.2 Python虚拟环境配置"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a27499554dce93bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "conda create --name PT python=3.7 \\\n",
    "conda activate PT \\\n",
    " \\# 安装pytorch \\\n",
    " \\# 若有显卡，当支持的cuda版本高于11.3时，安装对应pytorch。若无显卡，默认安装cpu版本 \\\n",
    "conda install pytorch==1.10.0 torchvision==0.11.0 torchaudio==0.10.0 cudatoolkit=11.3 -c pytorch \\\n",
    "pip install numpy \\\n",
    "pip install pandas \\\n",
    "pip install matplotlib"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a482e74ae0e053d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3 交互式运行"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a5cfaedd115409ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.0 模块导入和基础函数"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3600a28a8e618366"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# 模块导入\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:28:54.261679260Z",
     "start_time": "2024-09-03T11:28:53.811025255Z"
    }
   },
   "id": "35101aa3101019e4"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# 绝对坐标 → 位移矢量\n",
    "def diff(array):\n",
    "    diff_array = np.diff(array, axis=1)\n",
    "    padded_diff_array = np.concatenate([np.zeros((array.shape[0], 1, array.shape[2])), diff_array], axis=1)\n",
    "    initial_values = array[:, 0]\n",
    "    return padded_diff_array, initial_values\n",
    "\n",
    "# 绝对坐标 ← 位移矢量\n",
    "def diff_return(padded_diff_array, initial_values):\n",
    "    restored_array = np.cumsum(padded_diff_array, axis=1) + initial_values[:, np.newaxis, :]\n",
    "    return restored_array\n",
    "\n",
    "# 时间计算\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    mins = int(elapsed_time // 60)\n",
    "    secs = int(elapsed_time % 60)\n",
    "    return mins, secs\n",
    "\n",
    "\n",
    "# 定义轨迹数据的类\n",
    "class CustomDataset:\n",
    "    def __init__(self, data, labels, initial_values):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32)\n",
    "        self.initial_values = torch.tensor(initial_values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.labels[idx], self.initial_values[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:28:54.264301329Z",
     "start_time": "2024-09-03T11:28:54.263005532Z"
    }
   },
   "id": "e5cd6b79e8459c54"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 数据预处理"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c9d326a537ffb51"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def createSequence(data, hist_len=20, fut_len=30):\n",
    "    # 对每条轨迹分别切割获得数据和标签\n",
    "    trajs = []\n",
    "    for traj_id in set(data['id']):\n",
    "        data_one_veh = data.loc[data['id'] == traj_id]\n",
    "        data_one_veh = np.array(data_one_veh.loc[:, ['x', 'y']])\n",
    "        if data_one_veh.shape[0] <= hist_len + fut_len:\n",
    "            continue\n",
    "        window = 2\n",
    "        for i in range(0, data_one_veh.shape[0] - hist_len - fut_len, window):\n",
    "            # 过滤掉几乎静止的数据\n",
    "            if np.linalg.norm(data_one_veh[i] - data_one_veh[i:i + hist_len]) < 1 \\\n",
    "                    or np.linalg.norm(data_one_veh[i:i + hist_len] - data_one_veh[i + hist_len + fut_len]) < 1 \\\n",
    "                    or np.diff(data_one_veh[i:i + hist_len + fut_len], axis=0).max() > 5:\n",
    "                continue\n",
    "            trajs.append(data_one_veh[i:i + hist_len + fut_len])\n",
    "    trajs = np.array(trajs, dtype='float64')\n",
    "    # 为了能达到较好训练效果，采用前后时刻的位移矢量而非绝对坐标作为模型输入\n",
    "    padded_diff_array, initial_values = diff(trajs)\n",
    "    seq, labels = padded_diff_array[:, :20, :], padded_diff_array[:, 20:, :]\n",
    "    return seq, labels, initial_values\n",
    "\n",
    "def preprocess(dataset_path='./data', hist_len=20, fut_len=30, output_path='./data/processed_data.pkl'):\n",
    "    print('————————————数据预处理开始————————————')\n",
    "    train_data = pd.read_csv(f'./{dataset_path}/left_veh_train.csv')\n",
    "    test_data = pd.read_csv(f'./{dataset_path}/left_veh_test.csv')\n",
    "    # 数据分割\n",
    "    train_seq, train_labels, train_initial_values = createSequence(train_data, hist_len=hist_len, fut_len=fut_len)\n",
    "    test_seq, test_labels, test_initial_values = createSequence(test_data, hist_len=hist_len, fut_len=fut_len)\n",
    "    save_data = (train_seq, train_labels, train_initial_values, test_seq, test_labels, test_initial_values)\n",
    "\n",
    "    with open(output_path, 'wb') as file:\n",
    "        pickle.dump(save_data, file)\n",
    "    print('\\n————————————数据预处理结束————————————\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:28:54.270610171Z",
     "start_time": "2024-09-03T11:28:54.266492745Z"
    }
   },
   "id": "9349c74612d76de1"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————数据预处理开始————————————\n",
      "\n",
      "————————————数据预处理结束————————————\n"
     ]
    }
   ],
   "source": [
    "preprocess(dataset_path='./data', hist_len=20, fut_len=30, output_path='./data/processed_data.pkl')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:28:54.379676066Z",
     "start_time": "2024-09-03T11:28:54.271140783Z"
    }
   },
   "id": "6df81b6d1fe9326e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.2 模型定义与训练"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb267782671f91f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### 3.2.1 模型定义"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5641d40e98c41201"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# Encoder采用了一层全连接层，四层LSTM，并且采用了dropout来降低过拟合；\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 input_size = 2,\n",
    "                 embedding_size = 128,\n",
    "                 hidden_size = 256,\n",
    "                 n_layers = 4,\n",
    "                 dropout = 0.5):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.linear = nn.Linear(input_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers,\n",
    "                           dropout = dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: input batch data, size: [sequence len, batch size, feature size]\n",
    "        for the trajectory data, size(x) is [20, batch size, 2]\n",
    "        \"\"\"\n",
    "        # embedded: [sequence len, batch size, embedding size]\n",
    "        embedded = self.dropout(F.relu(self.linear(x)))\n",
    "        output, (hidden, cell) = self.rnn(embedded)\n",
    "        # hidden = [n layers * n directions, batch size, hidden size]\n",
    "        # cell = [n layers * n directions, batch size, hidden size]\n",
    "        # the n direction is 1 since we are not using bidirectional RNNs\n",
    "        return hidden, cell\n",
    "\n",
    "# Decoder的结构和Encoder的结构基本一致，区别在于Decoder每次接受输入的序列长度只有1，然后每次Decoder的输出都作为下一个时间点的预测。\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 output_size=2,\n",
    "                 embedding_size=128,\n",
    "                 hidden_size=256,\n",
    "                 n_layers=4,\n",
    "                 dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Linear(output_size, embedding_size)\n",
    "        self.rnn = nn.LSTM(embedding_size, hidden_size, n_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        \"\"\"\n",
    "        x : input batch data, size(x): [batch size, feature size]\n",
    "        \"\"\"\n",
    "        x = x.unsqueeze(0)\n",
    "        embedded = self.dropout(F.relu(self.embedding(x)))\n",
    "        output, (hidden, cell) = self.rnn(embedded, (hidden, cell))\n",
    "\n",
    "        # prediction = [batch size, output size]\n",
    "        prediction = self.linear(output.squeeze(0))\n",
    "\n",
    "        return prediction, hidden, cell\n",
    "\n",
    "\n",
    "# 最终的Seq2Seq模型结合了Encoder和Decoder进行预测\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        assert encoder.hidden_size == decoder.hidden_size, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, x, y, teacher_forcing_ratio=0.5):\n",
    "        \"\"\"\n",
    "        x = [observed sequence len, batch size, feature size]\n",
    "        y = [target sequence len, batch size, feature size]\n",
    "        \"\"\"\n",
    "        batch_size = x.shape[1]\n",
    "        target_len = y.shape[0]\n",
    "\n",
    "        outputs = torch.zeros(y.shape).to(self.device)\n",
    "        hidden, cell = self.encoder(x)\n",
    "        decoder_input = x[-1, :, :]\n",
    "\n",
    "        for i in range(target_len):\n",
    "            # 解码每一个时间步\n",
    "            output, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            outputs[i] = output\n",
    "\n",
    "            # 决定是否使用teacher forcing\n",
    "            teacher_forcing = random.random() < teacher_forcing_ratio\n",
    "            decoder_input = y[i] if teacher_forcing else output\n",
    "\n",
    "        return outputs"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:28:54.413421710Z",
     "start_time": "2024-09-03T11:28:54.384864670Z"
    }
   },
   "id": "178a117e4f953ab8"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer, criterion, dev):\n",
    "    # 进行一轮训练\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for i, (x, y, train_ini) in enumerate(dataloader):\n",
    "        x = x.transpose(0, 1).to(dev)\n",
    "        y = y.transpose(0, 1).to(dev)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x, y)\n",
    "        loss = criterion(torch.cumsum(y_pred, dim=0), torch.cumsum(y, dim=0))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "def train(input_path='./data/processed_data.pkl', model='seq2seq', epochs=100, saved_model_path=\"./results/model/best_seq2seq.pt\"):\n",
    "    print('————————————模型训练开始————————————')\n",
    "    BATCH_SIZE = 64\n",
    "    INPUT_DIM = 2\n",
    "    OUTPUT_DIM = 2\n",
    "    ENC_EMB_DIM = 128\n",
    "    DEC_EMB_DIM = 128\n",
    "    HID_DIM = 256\n",
    "    N_LAYERS = 4\n",
    "    ENC_DROPOUT = 0.5\n",
    "    DEC_DROPOUT = 0.5\n",
    "\n",
    "    with open(input_path, 'rb') as file:\n",
    "        train_seq, train_labels, train_initial_values, val_seq, val_labels, val_initial_values = pickle.load(file)\n",
    "    # 组织数据\n",
    "    train_dataset = CustomDataset(train_seq, train_labels, train_initial_values)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # 加载LSTM Encoder-Decoder模型\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "    dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Seq2Seq(enc, dec, dev).to(dev)\n",
    "\n",
    "    best_train_loss = float('inf')\n",
    "\n",
    "    # 若存在已保存的模型可以继续训练\n",
    "    if os.path.isfile(saved_model_path):\n",
    "        model.load_state_dict(torch.load(saved_model_path))\n",
    "        print(\"successfully load previous best model parameters\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, dev)\n",
    "        end_time = time.time()\n",
    "        mins, secs = epoch_time(start_time, end_time)\n",
    "        print(F'Epoch: {epoch + 1:02} | Time: {mins}m {secs}s')\n",
    "        print(F'Train Loss: {train_loss:.3f}')\n",
    "        # 保存模型\n",
    "        if train_loss < best_train_loss:\n",
    "            best_train_loss = train_loss\n",
    "            torch.save(model.state_dict(), saved_model_path)\n",
    "            print(f\"Best epoch:{epoch+1}\")\n",
    "    print('————————————模型训练结束————————————\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:28:54.413869689Z",
     "start_time": "2024-09-03T11:28:54.388661186Z"
    }
   },
   "id": "8e11c09691e2ee05"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————模型训练开始————————————\n",
      "Epoch: 01 | Time: 0m 1s\n",
      "Train Loss: 4.746\n",
      "Best epoch:1\n",
      "Epoch: 02 | Time: 0m 1s\n",
      "Train Loss: 0.801\n",
      "Best epoch:2\n",
      "Epoch: 03 | Time: 0m 1s\n",
      "Train Loss: 0.539\n",
      "Best epoch:3\n",
      "Epoch: 04 | Time: 0m 1s\n",
      "Train Loss: 0.436\n",
      "Best epoch:4\n",
      "Epoch: 05 | Time: 0m 1s\n",
      "Train Loss: 0.319\n",
      "Best epoch:5\n",
      "Epoch: 06 | Time: 0m 1s\n",
      "Train Loss: 0.321\n",
      "Epoch: 07 | Time: 0m 1s\n",
      "Train Loss: 0.365\n",
      "Epoch: 08 | Time: 0m 1s\n",
      "Train Loss: 0.335\n",
      "Epoch: 09 | Time: 0m 1s\n",
      "Train Loss: 0.367\n",
      "Epoch: 10 | Time: 0m 1s\n",
      "Train Loss: 0.285\n",
      "Best epoch:10\n",
      "Epoch: 11 | Time: 0m 1s\n",
      "Train Loss: 0.221\n",
      "Best epoch:11\n",
      "Epoch: 12 | Time: 0m 1s\n",
      "Train Loss: 0.228\n",
      "Epoch: 13 | Time: 0m 1s\n",
      "Train Loss: 0.245\n",
      "Epoch: 14 | Time: 0m 1s\n",
      "Train Loss: 0.225\n",
      "Epoch: 15 | Time: 0m 1s\n",
      "Train Loss: 0.211\n",
      "Best epoch:15\n",
      "Epoch: 16 | Time: 0m 1s\n",
      "Train Loss: 0.205\n",
      "Best epoch:16\n",
      "Epoch: 17 | Time: 0m 1s\n",
      "Train Loss: 0.181\n",
      "Best epoch:17\n",
      "Epoch: 18 | Time: 0m 1s\n",
      "Train Loss: 0.180\n",
      "Best epoch:18\n",
      "Epoch: 19 | Time: 0m 1s\n",
      "Train Loss: 0.239\n",
      "Epoch: 20 | Time: 0m 1s\n",
      "Train Loss: 0.141\n",
      "Best epoch:20\n",
      "Epoch: 21 | Time: 0m 1s\n",
      "Train Loss: 0.166\n",
      "Epoch: 22 | Time: 0m 1s\n",
      "Train Loss: 0.229\n",
      "Epoch: 23 | Time: 0m 1s\n",
      "Train Loss: 0.202\n",
      "Epoch: 24 | Time: 0m 1s\n",
      "Train Loss: 0.194\n",
      "Epoch: 25 | Time: 0m 1s\n",
      "Train Loss: 0.162\n",
      "Epoch: 26 | Time: 0m 1s\n",
      "Train Loss: 0.152\n",
      "Epoch: 27 | Time: 0m 1s\n",
      "Train Loss: 0.193\n",
      "Epoch: 28 | Time: 0m 1s\n",
      "Train Loss: 0.220\n",
      "Epoch: 29 | Time: 0m 1s\n",
      "Train Loss: 0.155\n",
      "Epoch: 30 | Time: 0m 1s\n",
      "Train Loss: 0.156\n",
      "Epoch: 31 | Time: 0m 1s\n",
      "Train Loss: 0.141\n",
      "Best epoch:31\n",
      "Epoch: 32 | Time: 0m 1s\n",
      "Train Loss: 0.198\n",
      "Epoch: 33 | Time: 0m 1s\n",
      "Train Loss: 0.142\n",
      "Epoch: 34 | Time: 0m 1s\n",
      "Train Loss: 0.170\n",
      "Epoch: 35 | Time: 0m 1s\n",
      "Train Loss: 0.241\n",
      "Epoch: 36 | Time: 0m 1s\n",
      "Train Loss: 0.143\n",
      "Epoch: 37 | Time: 0m 1s\n",
      "Train Loss: 0.121\n",
      "Best epoch:37\n",
      "Epoch: 38 | Time: 0m 1s\n",
      "Train Loss: 0.120\n",
      "Best epoch:38\n",
      "Epoch: 39 | Time: 0m 1s\n",
      "Train Loss: 0.124\n",
      "Epoch: 40 | Time: 0m 1s\n",
      "Train Loss: 0.126\n",
      "Epoch: 41 | Time: 0m 1s\n",
      "Train Loss: 0.153\n",
      "Epoch: 42 | Time: 0m 1s\n",
      "Train Loss: 0.168\n",
      "Epoch: 43 | Time: 0m 1s\n",
      "Train Loss: 0.171\n",
      "Epoch: 44 | Time: 0m 1s\n",
      "Train Loss: 0.144\n",
      "Epoch: 45 | Time: 0m 1s\n",
      "Train Loss: 0.106\n",
      "Best epoch:45\n",
      "Epoch: 46 | Time: 0m 1s\n",
      "Train Loss: 0.109\n",
      "Epoch: 47 | Time: 0m 1s\n",
      "Train Loss: 0.135\n",
      "Epoch: 48 | Time: 0m 1s\n",
      "Train Loss: 0.148\n",
      "Epoch: 49 | Time: 0m 1s\n",
      "Train Loss: 0.171\n",
      "Epoch: 50 | Time: 0m 1s\n",
      "Train Loss: 0.117\n",
      "Epoch: 51 | Time: 0m 1s\n",
      "Train Loss: 0.106\n",
      "Best epoch:51\n",
      "Epoch: 52 | Time: 0m 1s\n",
      "Train Loss: 0.102\n",
      "Best epoch:52\n",
      "Epoch: 53 | Time: 0m 1s\n",
      "Train Loss: 0.109\n",
      "Epoch: 54 | Time: 0m 1s\n",
      "Train Loss: 0.122\n",
      "Epoch: 55 | Time: 0m 1s\n",
      "Train Loss: 0.142\n",
      "Epoch: 56 | Time: 0m 1s\n",
      "Train Loss: 0.142\n",
      "Epoch: 57 | Time: 0m 1s\n",
      "Train Loss: 0.122\n",
      "Epoch: 58 | Time: 0m 1s\n",
      "Train Loss: 0.129\n",
      "Epoch: 59 | Time: 0m 1s\n",
      "Train Loss: 0.120\n",
      "Epoch: 60 | Time: 0m 1s\n",
      "Train Loss: 0.104\n",
      "Epoch: 61 | Time: 0m 1s\n",
      "Train Loss: 0.093\n",
      "Best epoch:61\n",
      "Epoch: 62 | Time: 0m 1s\n",
      "Train Loss: 0.182\n",
      "Epoch: 63 | Time: 0m 1s\n",
      "Train Loss: 0.102\n",
      "Epoch: 64 | Time: 0m 1s\n",
      "Train Loss: 0.094\n",
      "Epoch: 65 | Time: 0m 1s\n",
      "Train Loss: 0.100\n",
      "Epoch: 66 | Time: 0m 1s\n",
      "Train Loss: 0.097\n",
      "Epoch: 67 | Time: 0m 1s\n",
      "Train Loss: 0.119\n",
      "Epoch: 68 | Time: 0m 1s\n",
      "Train Loss: 0.098\n",
      "Epoch: 69 | Time: 0m 1s\n",
      "Train Loss: 0.102\n",
      "Epoch: 70 | Time: 0m 1s\n",
      "Train Loss: 0.133\n",
      "Epoch: 71 | Time: 0m 1s\n",
      "Train Loss: 0.083\n",
      "Best epoch:71\n",
      "Epoch: 72 | Time: 0m 1s\n",
      "Train Loss: 0.098\n",
      "Epoch: 73 | Time: 0m 1s\n",
      "Train Loss: 0.095\n",
      "Epoch: 74 | Time: 0m 1s\n",
      "Train Loss: 0.096\n",
      "Epoch: 75 | Time: 0m 1s\n",
      "Train Loss: 0.081\n",
      "Best epoch:75\n",
      "Epoch: 76 | Time: 0m 1s\n",
      "Train Loss: 0.098\n",
      "Epoch: 77 | Time: 0m 1s\n",
      "Train Loss: 0.112\n",
      "Epoch: 78 | Time: 0m 1s\n",
      "Train Loss: 0.085\n",
      "Epoch: 79 | Time: 0m 1s\n",
      "Train Loss: 0.128\n",
      "Epoch: 80 | Time: 0m 1s\n",
      "Train Loss: 0.125\n",
      "Epoch: 81 | Time: 0m 1s\n",
      "Train Loss: 0.119\n",
      "Epoch: 82 | Time: 0m 1s\n",
      "Train Loss: 0.095\n",
      "Epoch: 83 | Time: 0m 1s\n",
      "Train Loss: 0.099\n",
      "Epoch: 84 | Time: 0m 1s\n",
      "Train Loss: 0.085\n",
      "Epoch: 85 | Time: 0m 1s\n",
      "Train Loss: 0.325\n",
      "Epoch: 86 | Time: 0m 1s\n",
      "Train Loss: 0.114\n",
      "Epoch: 87 | Time: 0m 1s\n",
      "Train Loss: 0.090\n",
      "Epoch: 88 | Time: 0m 1s\n",
      "Train Loss: 0.115\n",
      "Epoch: 89 | Time: 0m 1s\n",
      "Train Loss: 0.087\n",
      "Epoch: 90 | Time: 0m 1s\n",
      "Train Loss: 0.112\n",
      "Epoch: 91 | Time: 0m 1s\n",
      "Train Loss: 0.075\n",
      "Best epoch:91\n",
      "Epoch: 92 | Time: 0m 1s\n",
      "Train Loss: 0.076\n",
      "Epoch: 93 | Time: 0m 1s\n",
      "Train Loss: 0.072\n",
      "Best epoch:93\n",
      "Epoch: 94 | Time: 0m 1s\n",
      "Train Loss: 0.083\n",
      "Epoch: 95 | Time: 0m 1s\n",
      "Train Loss: 0.082\n",
      "Epoch: 96 | Time: 0m 1s\n",
      "Train Loss: 0.083\n",
      "Epoch: 97 | Time: 0m 1s\n",
      "Train Loss: 0.078\n",
      "Epoch: 98 | Time: 0m 1s\n",
      "Train Loss: 0.088\n",
      "Epoch: 99 | Time: 0m 1s\n",
      "Train Loss: 0.068\n",
      "Best epoch:99\n",
      "Epoch: 100 | Time: 0m 1s\n",
      "Train Loss: 0.073\n",
      "Epoch: 101 | Time: 0m 1s\n",
      "Train Loss: 0.074\n",
      "Epoch: 102 | Time: 0m 1s\n",
      "Train Loss: 0.069\n",
      "Epoch: 103 | Time: 0m 1s\n",
      "Train Loss: 0.074\n",
      "Epoch: 104 | Time: 0m 1s\n",
      "Train Loss: 0.078\n",
      "Epoch: 105 | Time: 0m 1s\n",
      "Train Loss: 0.072\n",
      "Epoch: 106 | Time: 0m 1s\n",
      "Train Loss: 0.079\n",
      "Epoch: 107 | Time: 0m 1s\n",
      "Train Loss: 0.079\n",
      "Epoch: 108 | Time: 0m 1s\n",
      "Train Loss: 0.083\n",
      "Epoch: 109 | Time: 0m 1s\n",
      "Train Loss: 0.072\n",
      "Epoch: 110 | Time: 0m 1s\n",
      "Train Loss: 0.066\n",
      "Best epoch:110\n",
      "Epoch: 111 | Time: 0m 1s\n",
      "Train Loss: 0.082\n",
      "Epoch: 112 | Time: 0m 1s\n",
      "Train Loss: 0.085\n",
      "Epoch: 113 | Time: 0m 1s\n",
      "Train Loss: 0.084\n",
      "Epoch: 114 | Time: 0m 1s\n",
      "Train Loss: 0.096\n",
      "Epoch: 115 | Time: 0m 1s\n",
      "Train Loss: 0.072\n",
      "Epoch: 116 | Time: 0m 1s\n",
      "Train Loss: 0.087\n",
      "Epoch: 117 | Time: 0m 1s\n",
      "Train Loss: 0.071\n",
      "Epoch: 118 | Time: 0m 1s\n",
      "Train Loss: 0.090\n",
      "Epoch: 119 | Time: 0m 1s\n",
      "Train Loss: 0.074\n",
      "Epoch: 120 | Time: 0m 1s\n",
      "Train Loss: 0.062\n",
      "Best epoch:120\n",
      "Epoch: 121 | Time: 0m 1s\n",
      "Train Loss: 0.073\n",
      "Epoch: 122 | Time: 0m 1s\n",
      "Train Loss: 0.079\n",
      "Epoch: 123 | Time: 0m 1s\n",
      "Train Loss: 0.071\n",
      "Epoch: 124 | Time: 0m 1s\n",
      "Train Loss: 0.107\n",
      "Epoch: 125 | Time: 0m 1s\n",
      "Train Loss: 0.092\n",
      "Epoch: 126 | Time: 0m 1s\n",
      "Train Loss: 0.090\n",
      "Epoch: 127 | Time: 0m 1s\n",
      "Train Loss: 0.063\n",
      "Epoch: 128 | Time: 0m 1s\n",
      "Train Loss: 0.054\n",
      "Best epoch:128\n",
      "Epoch: 129 | Time: 0m 1s\n",
      "Train Loss: 0.062\n",
      "Epoch: 130 | Time: 0m 1s\n",
      "Train Loss: 0.057\n",
      "Epoch: 131 | Time: 0m 1s\n",
      "Train Loss: 0.073\n",
      "Epoch: 132 | Time: 0m 1s\n",
      "Train Loss: 0.084\n",
      "Epoch: 133 | Time: 0m 1s\n",
      "Train Loss: 0.060\n",
      "Epoch: 134 | Time: 0m 1s\n",
      "Train Loss: 0.060\n",
      "Epoch: 135 | Time: 0m 1s\n",
      "Train Loss: 0.067\n",
      "Epoch: 136 | Time: 0m 1s\n",
      "Train Loss: 0.063\n",
      "Epoch: 137 | Time: 0m 1s\n",
      "Train Loss: 0.074\n",
      "Epoch: 138 | Time: 0m 1s\n",
      "Train Loss: 0.065\n",
      "Epoch: 139 | Time: 0m 1s\n",
      "Train Loss: 0.073\n",
      "Epoch: 140 | Time: 0m 1s\n",
      "Train Loss: 0.084\n",
      "Epoch: 141 | Time: 0m 1s\n",
      "Train Loss: 0.053\n",
      "Best epoch:141\n",
      "Epoch: 142 | Time: 0m 1s\n",
      "Train Loss: 0.061\n",
      "Epoch: 143 | Time: 0m 1s\n",
      "Train Loss: 0.050\n",
      "Best epoch:143\n",
      "Epoch: 144 | Time: 0m 1s\n",
      "Train Loss: 0.052\n",
      "Epoch: 145 | Time: 0m 1s\n",
      "Train Loss: 0.076\n",
      "Epoch: 146 | Time: 0m 1s\n",
      "Train Loss: 0.080\n",
      "Epoch: 147 | Time: 0m 1s\n",
      "Train Loss: 0.058\n",
      "Epoch: 148 | Time: 0m 1s\n",
      "Train Loss: 0.058\n",
      "Epoch: 149 | Time: 0m 1s\n",
      "Train Loss: 0.052\n",
      "Epoch: 150 | Time: 0m 1s\n",
      "Train Loss: 0.056\n",
      "Epoch: 151 | Time: 0m 1s\n",
      "Train Loss: 0.054\n",
      "Epoch: 152 | Time: 0m 1s\n",
      "Train Loss: 0.062\n",
      "Epoch: 153 | Time: 0m 1s\n",
      "Train Loss: 0.057\n",
      "Epoch: 154 | Time: 0m 1s\n",
      "Train Loss: 0.052\n",
      "Epoch: 155 | Time: 0m 1s\n",
      "Train Loss: 0.057\n",
      "Epoch: 156 | Time: 0m 1s\n",
      "Train Loss: 0.065\n",
      "Epoch: 157 | Time: 0m 1s\n",
      "Train Loss: 0.047\n",
      "Best epoch:157\n",
      "Epoch: 158 | Time: 0m 1s\n",
      "Train Loss: 0.052\n",
      "Epoch: 159 | Time: 0m 1s\n",
      "Train Loss: 0.058\n",
      "Epoch: 160 | Time: 0m 1s\n",
      "Train Loss: 0.047\n",
      "Best epoch:160\n",
      "Epoch: 161 | Time: 0m 1s\n",
      "Train Loss: 0.063\n",
      "Epoch: 162 | Time: 0m 1s\n",
      "Train Loss: 0.051\n",
      "Epoch: 163 | Time: 0m 1s\n",
      "Train Loss: 0.065\n",
      "Epoch: 164 | Time: 0m 1s\n",
      "Train Loss: 0.064\n",
      "Epoch: 165 | Time: 0m 1s\n",
      "Train Loss: 0.057\n",
      "Epoch: 166 | Time: 0m 1s\n",
      "Train Loss: 0.051\n",
      "Epoch: 167 | Time: 0m 1s\n",
      "Train Loss: 0.053\n",
      "Epoch: 168 | Time: 0m 1s\n",
      "Train Loss: 0.050\n",
      "Epoch: 169 | Time: 0m 1s\n",
      "Train Loss: 0.052\n",
      "Epoch: 170 | Time: 0m 1s\n",
      "Train Loss: 0.062\n",
      "Epoch: 171 | Time: 0m 1s\n",
      "Train Loss: 0.052\n",
      "Epoch: 172 | Time: 0m 1s\n",
      "Train Loss: 0.047\n",
      "Best epoch:172\n",
      "Epoch: 173 | Time: 0m 1s\n",
      "Train Loss: 0.054\n",
      "Epoch: 174 | Time: 0m 1s\n",
      "Train Loss: 0.059\n",
      "Epoch: 175 | Time: 0m 1s\n",
      "Train Loss: 0.052\n",
      "Epoch: 176 | Time: 0m 1s\n",
      "Train Loss: 0.050\n",
      "Epoch: 177 | Time: 0m 1s\n",
      "Train Loss: 0.060\n",
      "Epoch: 178 | Time: 0m 1s\n",
      "Train Loss: 0.082\n",
      "Epoch: 179 | Time: 0m 1s\n",
      "Train Loss: 0.055\n",
      "Epoch: 180 | Time: 0m 1s\n",
      "Train Loss: 0.044\n",
      "Best epoch:180\n",
      "Epoch: 181 | Time: 0m 1s\n",
      "Train Loss: 0.042\n",
      "Best epoch:181\n",
      "Epoch: 182 | Time: 0m 1s\n",
      "Train Loss: 0.061\n",
      "Epoch: 183 | Time: 0m 1s\n",
      "Train Loss: 0.050\n",
      "Epoch: 184 | Time: 0m 1s\n",
      "Train Loss: 0.045\n",
      "Epoch: 185 | Time: 0m 1s\n",
      "Train Loss: 0.065\n",
      "Epoch: 186 | Time: 0m 1s\n",
      "Train Loss: 0.042\n",
      "Best epoch:186\n",
      "Epoch: 187 | Time: 0m 1s\n",
      "Train Loss: 0.050\n",
      "Epoch: 188 | Time: 0m 1s\n",
      "Train Loss: 0.044\n",
      "Epoch: 189 | Time: 0m 1s\n",
      "Train Loss: 0.048\n",
      "Epoch: 190 | Time: 0m 1s\n",
      "Train Loss: 0.050\n",
      "Epoch: 191 | Time: 0m 1s\n",
      "Train Loss: 0.047\n",
      "Epoch: 192 | Time: 0m 1s\n",
      "Train Loss: 0.049\n",
      "Epoch: 193 | Time: 0m 1s\n",
      "Train Loss: 0.046\n",
      "Epoch: 194 | Time: 0m 1s\n",
      "Train Loss: 0.054\n",
      "Epoch: 195 | Time: 0m 1s\n",
      "Train Loss: 0.045\n",
      "Epoch: 196 | Time: 0m 1s\n",
      "Train Loss: 0.052\n",
      "Epoch: 197 | Time: 0m 1s\n",
      "Train Loss: 0.053\n",
      "Epoch: 198 | Time: 0m 1s\n",
      "Train Loss: 0.057\n",
      "Epoch: 199 | Time: 0m 1s\n",
      "Train Loss: 0.053\n",
      "Epoch: 200 | Time: 0m 1s\n",
      "Train Loss: 0.051\n",
      "Epoch: 201 | Time: 0m 1s\n",
      "Train Loss: 0.045\n",
      "Epoch: 202 | Time: 0m 1s\n",
      "Train Loss: 0.045\n",
      "Epoch: 203 | Time: 0m 1s\n",
      "Train Loss: 0.042\n",
      "Epoch: 204 | Time: 0m 1s\n",
      "Train Loss: 0.043\n",
      "Epoch: 205 | Time: 0m 1s\n",
      "Train Loss: 0.046\n",
      "Epoch: 206 | Time: 0m 1s\n",
      "Train Loss: 0.044\n",
      "Epoch: 207 | Time: 0m 1s\n",
      "Train Loss: 0.039\n",
      "Best epoch:207\n",
      "Epoch: 208 | Time: 0m 1s\n",
      "Train Loss: 0.045\n",
      "Epoch: 209 | Time: 0m 1s\n",
      "Train Loss: 0.044\n",
      "Epoch: 210 | Time: 0m 1s\n",
      "Train Loss: 0.050\n",
      "Epoch: 211 | Time: 0m 1s\n",
      "Train Loss: 0.048\n",
      "Epoch: 212 | Time: 0m 1s\n",
      "Train Loss: 0.043\n",
      "Epoch: 213 | Time: 0m 1s\n",
      "Train Loss: 0.045\n",
      "Epoch: 214 | Time: 0m 1s\n",
      "Train Loss: 0.043\n",
      "Epoch: 215 | Time: 0m 1s\n",
      "Train Loss: 0.046\n",
      "Epoch: 216 | Time: 0m 1s\n",
      "Train Loss: 0.042\n",
      "Epoch: 217 | Time: 0m 1s\n",
      "Train Loss: 0.046\n",
      "Epoch: 218 | Time: 0m 1s\n",
      "Train Loss: 0.043\n",
      "Epoch: 219 | Time: 0m 1s\n",
      "Train Loss: 0.040\n",
      "Epoch: 220 | Time: 0m 1s\n",
      "Train Loss: 0.040\n",
      "Epoch: 221 | Time: 0m 1s\n",
      "Train Loss: 0.046\n",
      "Epoch: 222 | Time: 0m 1s\n",
      "Train Loss: 0.046\n",
      "Epoch: 223 | Time: 0m 1s\n",
      "Train Loss: 0.044\n",
      "Epoch: 224 | Time: 0m 1s\n",
      "Train Loss: 0.044\n",
      "Epoch: 225 | Time: 0m 1s\n",
      "Train Loss: 0.039\n",
      "Best epoch:225\n",
      "Epoch: 226 | Time: 0m 1s\n",
      "Train Loss: 0.046\n",
      "Epoch: 227 | Time: 0m 1s\n",
      "Train Loss: 0.044\n",
      "Epoch: 228 | Time: 0m 1s\n",
      "Train Loss: 0.040\n",
      "Epoch: 229 | Time: 0m 1s\n",
      "Train Loss: 0.041\n",
      "Epoch: 230 | Time: 0m 1s\n",
      "Train Loss: 0.037\n",
      "Best epoch:230\n",
      "Epoch: 231 | Time: 0m 1s\n",
      "Train Loss: 0.044\n",
      "Epoch: 232 | Time: 0m 1s\n",
      "Train Loss: 0.041\n",
      "Epoch: 233 | Time: 0m 1s\n",
      "Train Loss: 0.041\n",
      "Epoch: 234 | Time: 0m 1s\n",
      "Train Loss: 0.039\n",
      "Epoch: 235 | Time: 0m 1s\n",
      "Train Loss: 0.047\n",
      "Epoch: 236 | Time: 0m 1s\n",
      "Train Loss: 0.040\n",
      "Epoch: 237 | Time: 0m 1s\n",
      "Train Loss: 0.037\n",
      "Epoch: 238 | Time: 0m 1s\n",
      "Train Loss: 0.039\n",
      "Epoch: 239 | Time: 0m 1s\n",
      "Train Loss: 0.043\n",
      "Epoch: 240 | Time: 0m 1s\n",
      "Train Loss: 0.036\n",
      "Best epoch:240\n",
      "Epoch: 241 | Time: 0m 1s\n",
      "Train Loss: 0.035\n",
      "Best epoch:241\n",
      "Epoch: 242 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Best epoch:242\n",
      "Epoch: 243 | Time: 0m 1s\n",
      "Train Loss: 0.035\n",
      "Epoch: 244 | Time: 0m 1s\n",
      "Train Loss: 0.038\n",
      "Epoch: 245 | Time: 0m 1s\n",
      "Train Loss: 0.038\n",
      "Epoch: 246 | Time: 0m 1s\n",
      "Train Loss: 0.037\n",
      "Epoch: 247 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 248 | Time: 0m 1s\n",
      "Train Loss: 0.038\n",
      "Epoch: 249 | Time: 0m 1s\n",
      "Train Loss: 0.043\n",
      "Epoch: 250 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Best epoch:250\n",
      "Epoch: 251 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 252 | Time: 0m 1s\n",
      "Train Loss: 0.031\n",
      "Epoch: 253 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 254 | Time: 0m 1s\n",
      "Train Loss: 0.037\n",
      "Epoch: 255 | Time: 0m 1s\n",
      "Train Loss: 0.046\n",
      "Epoch: 256 | Time: 0m 1s\n",
      "Train Loss: 0.036\n",
      "Epoch: 257 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 258 | Time: 0m 1s\n",
      "Train Loss: 0.033\n",
      "Epoch: 259 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 260 | Time: 0m 1s\n",
      "Train Loss: 0.039\n",
      "Epoch: 261 | Time: 0m 1s\n",
      "Train Loss: 0.036\n",
      "Epoch: 262 | Time: 0m 1s\n",
      "Train Loss: 0.037\n",
      "Epoch: 263 | Time: 0m 1s\n",
      "Train Loss: 0.041\n",
      "Epoch: 264 | Time: 0m 1s\n",
      "Train Loss: 0.036\n",
      "Epoch: 265 | Time: 0m 1s\n",
      "Train Loss: 0.042\n",
      "Epoch: 266 | Time: 0m 1s\n",
      "Train Loss: 0.036\n",
      "Epoch: 267 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 268 | Time: 0m 1s\n",
      "Train Loss: 0.035\n",
      "Epoch: 269 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 270 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 271 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Best epoch:271\n",
      "Epoch: 272 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 273 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 274 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 275 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 276 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 277 | Time: 0m 1s\n",
      "Train Loss: 0.041\n",
      "Epoch: 278 | Time: 0m 1s\n",
      "Train Loss: 0.039\n",
      "Epoch: 279 | Time: 0m 1s\n",
      "Train Loss: 0.033\n",
      "Epoch: 280 | Time: 0m 1s\n",
      "Train Loss: 0.033\n",
      "Epoch: 281 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 282 | Time: 0m 1s\n",
      "Train Loss: 0.031\n",
      "Epoch: 283 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Best epoch:283\n",
      "Epoch: 284 | Time: 0m 1s\n",
      "Train Loss: 0.031\n",
      "Epoch: 285 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Epoch: 286 | Time: 0m 1s\n",
      "Train Loss: 0.028\n",
      "Best epoch:286\n",
      "Epoch: 287 | Time: 0m 1s\n",
      "Train Loss: 0.031\n",
      "Epoch: 288 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 289 | Time: 0m 1s\n",
      "Train Loss: 0.033\n",
      "Epoch: 290 | Time: 0m 1s\n",
      "Train Loss: 0.033\n",
      "Epoch: 291 | Time: 0m 1s\n",
      "Train Loss: 0.038\n",
      "Epoch: 292 | Time: 0m 1s\n",
      "Train Loss: 0.042\n",
      "Epoch: 293 | Time: 0m 1s\n",
      "Train Loss: 0.042\n",
      "Epoch: 294 | Time: 0m 1s\n",
      "Train Loss: 0.035\n",
      "Epoch: 295 | Time: 0m 1s\n",
      "Train Loss: 0.033\n",
      "Epoch: 296 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Epoch: 297 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 298 | Time: 0m 1s\n",
      "Train Loss: 0.033\n",
      "Epoch: 299 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 300 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 301 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 302 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 303 | Time: 0m 1s\n",
      "Train Loss: 0.031\n",
      "Epoch: 304 | Time: 0m 1s\n",
      "Train Loss: 0.036\n",
      "Epoch: 305 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 306 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 307 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 308 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 309 | Time: 0m 1s\n",
      "Train Loss: 0.045\n",
      "Epoch: 310 | Time: 0m 1s\n",
      "Train Loss: 0.041\n",
      "Epoch: 311 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 312 | Time: 0m 1s\n",
      "Train Loss: 0.037\n",
      "Epoch: 313 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 314 | Time: 0m 1s\n",
      "Train Loss: 0.028\n",
      "Best epoch:314\n",
      "Epoch: 315 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 316 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Epoch: 317 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 318 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Best epoch:318\n",
      "Epoch: 319 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 320 | Time: 0m 1s\n",
      "Train Loss: 0.031\n",
      "Epoch: 321 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Best epoch:321\n",
      "Epoch: 322 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 323 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Epoch: 324 | Time: 0m 1s\n",
      "Train Loss: 0.041\n",
      "Epoch: 325 | Time: 0m 1s\n",
      "Train Loss: 0.028\n",
      "Epoch: 326 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Epoch: 327 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Epoch: 328 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Epoch: 329 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Epoch: 330 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 331 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Best epoch:331\n",
      "Epoch: 332 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 333 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 334 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 335 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 336 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 337 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 338 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 339 | Time: 0m 1s\n",
      "Train Loss: 0.028\n",
      "Epoch: 340 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 341 | Time: 0m 1s\n",
      "Train Loss: 0.031\n",
      "Epoch: 342 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 343 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 344 | Time: 0m 1s\n",
      "Train Loss: 0.035\n",
      "Epoch: 345 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 346 | Time: 0m 1s\n",
      "Train Loss: 0.037\n",
      "Epoch: 347 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 348 | Time: 0m 1s\n",
      "Train Loss: 0.028\n",
      "Epoch: 349 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 350 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 351 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 352 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 353 | Time: 0m 1s\n",
      "Train Loss: 0.028\n",
      "Epoch: 354 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 355 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 356 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Best epoch:356\n",
      "Epoch: 357 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Best epoch:357\n",
      "Epoch: 358 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 359 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 360 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 361 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 362 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 363 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 364 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 365 | Time: 0m 1s\n",
      "Train Loss: 0.037\n",
      "Epoch: 366 | Time: 0m 1s\n",
      "Train Loss: 0.031\n",
      "Epoch: 367 | Time: 0m 1s\n",
      "Train Loss: 0.031\n",
      "Epoch: 368 | Time: 0m 1s\n",
      "Train Loss: 0.028\n",
      "Epoch: 369 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 370 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 371 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Best epoch:371\n",
      "Epoch: 372 | Time: 0m 1s\n",
      "Train Loss: 0.028\n",
      "Epoch: 373 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 374 | Time: 0m 1s\n",
      "Train Loss: 0.033\n",
      "Epoch: 375 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 376 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 377 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 378 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 379 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Best epoch:379\n",
      "Epoch: 380 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 381 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 382 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 383 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 384 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 385 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 386 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 387 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 388 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 389 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Best epoch:389\n",
      "Epoch: 390 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 391 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 392 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 393 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 394 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 395 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 396 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 397 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 398 | Time: 0m 1s\n",
      "Train Loss: 0.053\n",
      "Epoch: 399 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 400 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 401 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 402 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Best epoch:402\n",
      "Epoch: 403 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 404 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 405 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 406 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 407 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 408 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 409 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 410 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 411 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 412 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 413 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 414 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 415 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 416 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 417 | Time: 0m 1s\n",
      "Train Loss: 0.030\n",
      "Epoch: 418 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 419 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Best epoch:419\n",
      "Epoch: 420 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 421 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 422 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 423 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 424 | Time: 0m 1s\n",
      "Train Loss: 0.038\n",
      "Epoch: 425 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 426 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 427 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 428 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Best epoch:428\n",
      "Epoch: 429 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 430 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 431 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 432 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 433 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 434 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 435 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 436 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 437 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 438 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 439 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 440 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 441 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 442 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 443 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 444 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 445 | Time: 0m 1s\n",
      "Train Loss: 0.032\n",
      "Epoch: 446 | Time: 0m 1s\n",
      "Train Loss: 0.029\n",
      "Epoch: 447 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 448 | Time: 0m 1s\n",
      "Train Loss: 0.025\n",
      "Epoch: 449 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 450 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 451 | Time: 0m 1s\n",
      "Train Loss: 0.027\n",
      "Epoch: 452 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 453 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 454 | Time: 0m 1s\n",
      "Train Loss: 0.019\n",
      "Best epoch:454\n",
      "Epoch: 455 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 456 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 457 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 458 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 459 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 460 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 461 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 462 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 463 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 464 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 465 | Time: 0m 1s\n",
      "Train Loss: 0.034\n",
      "Epoch: 466 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 467 | Time: 0m 1s\n",
      "Train Loss: 0.026\n",
      "Epoch: 468 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 469 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 470 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 471 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 472 | Time: 0m 1s\n",
      "Train Loss: 0.019\n",
      "Best epoch:472\n",
      "Epoch: 473 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 474 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 475 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 476 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 477 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 478 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 479 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 480 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 481 | Time: 0m 1s\n",
      "Train Loss: 0.019\n",
      "Epoch: 482 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 483 | Time: 0m 1s\n",
      "Train Loss: 0.019\n",
      "Best epoch:483\n",
      "Epoch: 484 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 485 | Time: 0m 1s\n",
      "Train Loss: 0.018\n",
      "Best epoch:485\n",
      "Epoch: 486 | Time: 0m 1s\n",
      "Train Loss: 0.022\n",
      "Epoch: 487 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "Epoch: 488 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 489 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 490 | Time: 0m 1s\n",
      "Train Loss: 0.018\n",
      "Epoch: 491 | Time: 0m 1s\n",
      "Train Loss: 0.018\n",
      "Best epoch:491\n",
      "Epoch: 492 | Time: 0m 1s\n",
      "Train Loss: 0.019\n",
      "Epoch: 493 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 494 | Time: 0m 1s\n",
      "Train Loss: 0.024\n",
      "Epoch: 495 | Time: 0m 1s\n",
      "Train Loss: 0.028\n",
      "Epoch: 496 | Time: 0m 1s\n",
      "Train Loss: 0.020\n",
      "Epoch: 497 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 498 | Time: 0m 1s\n",
      "Train Loss: 0.019\n",
      "Epoch: 499 | Time: 0m 1s\n",
      "Train Loss: 0.023\n",
      "Epoch: 500 | Time: 0m 1s\n",
      "Train Loss: 0.021\n",
      "————————————模型训练结束————————————\n"
     ]
    }
   ],
   "source": [
    "train(input_path='./data/processed_data.pkl', model='seq2seq', epochs=500, saved_model_path=\"./results/model/best_seq2seq.pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:37:31.950215401Z",
     "start_time": "2024-09-03T11:28:54.391176113Z"
    }
   },
   "id": "ec557f7458bd2f0b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.3 模型评估"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a3a0d5d0ff59787"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# 评价指标计算\n",
    "def get_metrics(model, dataloader, metrics, dev):\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y, val_ini) in enumerate(dataloader):\n",
    "            x = x.transpose(0, 1).to(dev)\n",
    "            y = y.transpose(0, 1).to(dev)\n",
    "            # 不使用teacher-forcing\n",
    "            y_pred = model(x, y, teacher_forcing_ratio=0)\n",
    "\n",
    "            x = x.cpu().detach().numpy().transpose(1,0,2)\n",
    "            y = y.cpu().detach().numpy().transpose(1,0,2)\n",
    "            y_pred = y_pred.cpu().detach().numpy().transpose(1,0,2)\n",
    "            val_ini = val_ini.cpu().detach().numpy()\n",
    "\n",
    "            gt = diff_return(np.concatenate((x,y),axis=1), val_ini)\n",
    "            pred = diff_return(np.concatenate((x,y_pred),axis=1), val_ini)\n",
    "\n",
    "            DE = np.linalg.norm(gt[:,20:,:] - pred[:,20:,:], axis=2)\n",
    "            results = {}\n",
    "            \n",
    "            # 指标计算\n",
    "            if 'ADE' in metrics:\n",
    "                results['ADE'] = DE.mean()\n",
    "            if 'FDE' in metrics:\n",
    "                results['FDE'] = DE[:,-1].mean()\n",
    "    return results\n",
    "\n",
    "# 模型评估主函数\n",
    "def evaluate(input_path='./data/processed_data.pkl', saved_model_path=\"./results/model/best_seq2seq.pt\", metrics=None):\n",
    "    print('————————————模型评估开始————————————')\n",
    "    INPUT_DIM = 2\n",
    "    OUTPUT_DIM = 2\n",
    "    ENC_EMB_DIM = 128\n",
    "    DEC_EMB_DIM = 128\n",
    "    HID_DIM = 256\n",
    "    N_LAYERS = 4\n",
    "    ENC_DROPOUT = 0.5\n",
    "    DEC_DROPOUT = 0.5\n",
    "\n",
    "    # 加载数据\n",
    "    with open(input_path, 'rb') as file:\n",
    "        train_seq, train_labels, train_initial_values, val_seq, val_labels, val_initial_values = pickle.load(file)\n",
    "\n",
    "    val_dataset = CustomDataset(val_seq, val_labels, val_initial_values)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "\n",
    "    # 加载模型类\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "    dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Seq2Seq(enc, dec, dev).to(dev)\n",
    "\n",
    "    # 加载模型参数\n",
    "    if os.path.isfile(saved_model_path):\n",
    "        model.load_state_dict(torch.load(saved_model_path, map_location=torch.device(dev)))\n",
    "        print(\"successfully load previous best model parameters\")\n",
    "\n",
    "    # 计算评价指标\n",
    "    result_nums = 1\n",
    "    for num in range(result_nums):\n",
    "        val_loss = get_metrics(model, val_loader, metrics, dev)\n",
    "        print(val_loss)\n",
    "    print('————————————模型评估结束————————————\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:37:31.954829988Z",
     "start_time": "2024-09-03T11:37:31.950466517Z"
    }
   },
   "id": "8c0e7401f1db8e39"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————模型评估开始————————————\n",
      "successfully load previous best model parameters\n",
      "{'ADE': 0.7339827, 'FDE': 2.00366}\n",
      "————————————模型评估结束————————————\n"
     ]
    }
   ],
   "source": [
    "evaluate(input_path='./data/processed_data.pkl', saved_model_path=\"./results/model/best_seq2seq.pt\", metrics=['ADE','FDE'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:37:32.027312657Z",
     "start_time": "2024-09-03T11:37:31.955581591Z"
    }
   },
   "id": "d80fb994a73506f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 3.4 模型可视化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d1c3e14cd288a39"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def vis(model, dataloader, dev, vis_id, fig_save_path):\n",
    "    # 模型输入历史轨迹，获取预测轨迹并可视化\n",
    "    model.eval()\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (x, y, val_ini) in enumerate(dataloader):\n",
    "            x = x.transpose(0, 1).to(dev)\n",
    "            y = y.transpose(0, 1).to(dev)\n",
    "\n",
    "            # 不使用teacher-forcing\n",
    "            y_pred = model(x, y, teacher_forcing_ratio=0)\n",
    "\n",
    "            x1 = x.cpu().detach().numpy().transpose(1,0,2)\n",
    "            y1 = y.cpu().detach().numpy().transpose(1,0,2)\n",
    "            y_pred1 = y_pred.cpu().detach().numpy().transpose(1,0,2)\n",
    "            val_ini = val_ini.cpu().detach().numpy()\n",
    "\n",
    "            gt = diff_return(np.concatenate((x1,y1),axis=1), val_ini)\n",
    "            pred = diff_return(np.concatenate((x1,y_pred1),axis=1), val_ini)\n",
    "\n",
    "            plt.figure()\n",
    "            plt.plot(gt[vis_id, :21, 0], gt[vis_id, :21, 1], 'grey', label='hist_traj')\n",
    "            plt.plot(gt[vis_id, 20:, 0], gt[vis_id, 20:, 1], 'c', label='fut_traj')\n",
    "            plt.plot(gt[vis_id, -1, 0], gt[vis_id, -1, 1], 'co')\n",
    "            plt.plot(pred[vis_id, 20:, 0], pred[vis_id, 20:, 1], 'r', label='pred_traj')\n",
    "            plt.plot(pred[vis_id, -1, 0], pred[vis_id, -1, 1], 'ro')\n",
    "            plt.axis('equal')\n",
    "            plt.legend()\n",
    "            plt.savefig(fig_save_path, dpi=500)\n",
    "            plt.show()\n",
    "\n",
    "    return epoch_loss / len(dataloader)\n",
    "\n",
    "#模型可视化主函数\n",
    "def visualize(input_path='./data/processed_data.pkl', saved_model_path=\"./results/model/best_seq2seq.pt\", vis_id=119, fig_save_path='./results/fig/119.jpg'):\n",
    "    print(f'————————————可视化场景id为{vis_id}————————————')\n",
    "    INPUT_DIM = 2\n",
    "    OUTPUT_DIM = 2\n",
    "    ENC_EMB_DIM = 128\n",
    "    DEC_EMB_DIM = 128\n",
    "    HID_DIM = 256\n",
    "    N_LAYERS = 4\n",
    "    ENC_DROPOUT = 0.5\n",
    "    DEC_DROPOUT = 0.5\n",
    "\n",
    "    # 加载数据\n",
    "    with open(input_path, 'rb') as file:\n",
    "        train_seq, train_labels, train_initial_values, val_seq, val_labels, val_initial_values = pickle.load(file)\n",
    "\n",
    "    val_dataset = CustomDataset(val_seq, val_labels, val_initial_values)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=len(val_dataset), shuffle=False)\n",
    "\n",
    "    # 加载模型类\n",
    "    enc = Encoder(INPUT_DIM, ENC_EMB_DIM, HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "    dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, HID_DIM, N_LAYERS, DEC_DROPOUT)\n",
    "    dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = Seq2Seq(enc, dec, dev).to(dev)\n",
    "\n",
    "    # 加载模型参数\n",
    "    if os.path.isfile(saved_model_path):\n",
    "        model.load_state_dict(torch.load(saved_model_path, map_location=torch.device(dev)))\n",
    "        print(\"successfully load previous best model parameters\")\n",
    "\n",
    "    # 可视化\n",
    "    vis(model, val_loader, dev, vis_id, fig_save_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:37:32.032739204Z",
     "start_time": "2024-09-03T11:37:32.031704409Z"
    }
   },
   "id": "29e5a09bd0ce87b4"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "————————————可视化场景id为119————————————\n",
      "successfully load previous best model parameters\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(input_path='./data/processed_data.pkl', saved_model_path=\"./results/model/example_best_seq2seq.pt\", vis_id=119, fig_save_path='./results/fig/119.jpg')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-09-03T11:37:32.245692904Z",
     "start_time": "2024-09-03T11:37:32.033123631Z"
    }
   },
   "id": "46595575bdc14007"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
